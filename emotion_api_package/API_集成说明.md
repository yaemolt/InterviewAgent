# DAiSEEæƒ…æ„Ÿè¯†åˆ«API - å®Œæ•´é›†æˆè¯´æ˜

## ğŸ¯ æ¦‚è¿°

æœ¬APIåŸºäºä¼˜åŒ–åçš„DAiSEEæƒ…æ„Ÿè¯†åˆ«æ¨¡å‹ï¼Œæä¾›å››ä¸ªæƒ…æ„Ÿç»´åº¦çš„åˆ†æå’Œç»¼åˆè¯„åˆ†ï¼š

- **å››ä¸ªæƒ…æ„Ÿæ ‡ç­¾**: Boredom(æ— èŠ)ã€Engagement(å‚ä¸)ã€Confusion(å›°æƒ‘)ã€Frustration(æŒ«æŠ˜)
- **å æ¯”è®¡ç®—**: æ¯ä¸ªæƒ…æ„Ÿçš„å½’ä¸€åŒ–æ¦‚ç‡å’Œç™¾åˆ†æ¯”
- **æœ€ç»ˆæ‰“åˆ†**: 0-100åˆ†çš„ç»¼åˆæƒ…æ„Ÿè¯„åˆ†
- **å®æ—¶æ€§èƒ½**: å¹³å‡æ¨ç†æ—¶é—´ < 1ms

## âœ… æ¨¡å‹éªŒè¯ç»“æœ

### æƒé‡æœ‰æ•ˆæ€§éªŒè¯
- âœ… æ¨¡å‹æƒé‡å·²è®­ç»ƒï¼ˆæƒé‡å·®å¼‚: 0.059ï¼‰
- âœ… éªŒè¯MAE: 0.6295 ï¼ˆç›¸æ¯”åŸºç¡€æ¨¡å‹æå‡10.19%ï¼‰
- âœ… è®­ç»ƒè½®æ•°: 4ä¸ªepoch
- âœ… æ¨¡å‹å¤§å°: 2.4MBï¼ˆè½»é‡åŒ–è®¾è®¡ï¼‰

### æ€§èƒ½åŸºå‡†
- âš¡ å¹³å‡æ¨ç†æ—¶é—´: 0.86ms
- ğŸš€ æ€§èƒ½ç­‰çº§: ä¼˜ç§€ - é€‚åˆå®æ—¶åº”ç”¨
- ğŸ“Š GPUåŠ é€Ÿ: æ”¯æŒCUDA
- ğŸ’¾ å†…å­˜å ç”¨: ä½

## ğŸ­ è¾“å‡ºæ ¼å¼

### å®Œæ•´JSONå“åº”ç»“æ„
```json
{
  "timestamp": "2025-06-25T16:05:41.411037",
  "emotions": {
    "raw_scores": {
      "Boredom": 0.792,
      "Engagement": 2.315,
      "Confusion": 0.257,
      "Frustration": 0.155
    },
    "probabilities": {
      "Boredom": 0.149,
      "Engagement": 0.684,
      "Confusion": 0.087,
      "Frustration": 0.079
    },
    "percentages": {
      "Boredom": 14.9,
      "Engagement": 68.4,
      "Confusion": 8.7,
      "Frustration": 7.9
    }
  },
  "final_score": 59.33,
  "dominant_emotion": "Engagement",
  "confidence": 0.684,
  "interpretation": "ä¸­æ€§çŠ¶æ€ - æ­£å¸¸è¡¨ç°",
  "model_info": {
    "mae": 0.6295,
    "accuracy_improvement": "+10.19%"
  }
}
```

### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `timestamp` | string | é¢„æµ‹æ—¶é—´æˆ³ |
| `emotions.raw_scores` | object | åŸå§‹æ¨¡å‹è¾“å‡º (0-3èŒƒå›´) |
| `emotions.probabilities` | object | è½¯maxå½’ä¸€åŒ–æ¦‚ç‡ (0-1) |
| `emotions.percentages` | object | ç™¾åˆ†æ¯”è¡¨ç¤º (0-100%) |
| `final_score` | float | ç»¼åˆæƒ…æ„Ÿè¯„åˆ† (0-100åˆ†) |
| `dominant_emotion` | string | å æ¯”æœ€é«˜çš„æƒ…æ„Ÿ |
| `confidence` | float | ä¸»å¯¼æƒ…æ„Ÿçš„ç½®ä¿¡åº¦ |
| `interpretation` | string | åˆ†æ•°çš„æ–‡å­—è§£é‡Š |
| `model_info` | object | æ¨¡å‹æ€§èƒ½ä¿¡æ¯ |

## ğŸ”¢ è¯„åˆ†æœºåˆ¶

### åŠ æƒè¯„åˆ†ç®—æ³•
```
åŠ æƒåˆ†æ•° = Î£(æƒ…æ„Ÿæ¦‚ç‡ Ã— æƒ…æ„Ÿæƒé‡)
æœ€ç»ˆå¾—åˆ† = 50 + åŠ æƒåˆ†æ•° Ã— 25  # æ˜ å°„åˆ°0-100èŒƒå›´
```

### æƒ…æ„Ÿæƒé‡è®¾ç½®
- **Boredom(æ— èŠ)**: -1.0 (è´Ÿé¢æƒ…ç»ª)
- **Engagement(å‚ä¸)**: +1.0 (æ­£é¢æƒ…ç»ª)  
- **Confusion(å›°æƒ‘)**: -0.5 (è½»å¾®è´Ÿé¢)
- **Frustration(æŒ«æŠ˜)**: -1.5 (å¼ºçƒˆè´Ÿé¢)

### åˆ†æ•°åŒºé—´å«ä¹‰
- **75-100åˆ†**: ç§¯æçŠ¶æ€ - é«˜åº¦å‚ä¸å’Œä¸“æ³¨
- **60-74åˆ†**: è‰¯å¥½çŠ¶æ€ - ç§¯æå‚ä¸
- **40-59åˆ†**: ä¸­æ€§çŠ¶æ€ - æ­£å¸¸è¡¨ç°
- **25-39åˆ†**: è½»å¾®æ¶ˆæ - å¯èƒ½å‡ºç°å›°æƒ‘æˆ–æ— èŠ
- **0-24åˆ†**: æ¶ˆæçŠ¶æ€ - æ˜æ˜¾çš„æŒ«æŠ˜æˆ–ä¸¥é‡æ— èŠ

## ğŸš€ ä½¿ç”¨æ–¹å¼

### æ–¹å¼1: ç›´æ¥å¯¼å…¥ä½¿ç”¨

```python
from emotion_recognition_api import EmotionRecognitionAPI

# åˆå§‹åŒ–API
api = EmotionRecognitionAPI()

# é¢„æµ‹æƒ…æ„Ÿï¼ˆè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼‰
result = api.predict_emotions('video.mp4', is_base64=False)

# è·å–ç»“æœ
final_score = result['final_score']
emotions = result['emotions']['percentages']
print(f"æœ€ç»ˆå¾—åˆ†: {final_score:.2f}/100")
print(f"æƒ…æ„Ÿå æ¯”: {emotions}")
```

### æ–¹å¼2: Flask HTTP API

#### å¯åŠ¨æœåŠ¡
```bash
python emotion_recognition_api.py
# æœåŠ¡å°†åœ¨ http://localhost:5000 å¯åŠ¨
```

#### è°ƒç”¨API

**POST /predict** (Base64è§†é¢‘)
```python
import requests
import base64

# è¯»å–è§†é¢‘æ–‡ä»¶
with open('video.mp4', 'rb') as f:
    video_base64 = base64.b64encode(f.read()).decode()

# è°ƒç”¨API
response = requests.post('http://localhost:5000/predict', 
                        json={
                            'video': video_base64,
                            'is_base64': True
                        })

result = response.json()
```

**POST /predict_file** (æ–‡ä»¶ä¸Šä¼ )
```python
import requests

# ä¸Šä¼ è§†é¢‘æ–‡ä»¶
files = {'video': open('video.mp4', 'rb')}
response = requests.post('http://localhost:5000/predict_file', files=files)

result = response.json()
```

**GET /health** (å¥åº·æ£€æŸ¥)
```python
response = requests.get('http://localhost:5000/health')
status = response.json()
```

## ğŸ“Š ç¤ºä¾‹ç»“æœå±•ç¤º

### æ–‡å­—å¯è§†åŒ–
```
ğŸ­ å››ä¸ªæƒ…æ„Ÿç»´åº¦åˆ†æ:
ğŸ˜´ Boredom       0.792    0.149    14.9%
ğŸ˜Š Engagement    2.315    0.684    68.4%
ğŸ˜• Confusion     0.257    0.087     8.7%
ğŸ˜¤ Frustration   0.155    0.079     7.9%

ğŸ“ˆ æƒ…æ„Ÿå æ¯”å¯è§†åŒ–:
Boredom      |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘|  14.9%
Engagement   |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  68.4%
Confusion    |â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘|   8.7%
Frustration  |â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘|   7.9%
```

### åº”ç”¨å»ºè®®
æ ¹æ®æœ€ç»ˆå¾—åˆ†è‡ªåŠ¨ç”Ÿæˆå»ºè®®ï¼š
- ğŸ“ çŠ¶æ€æ­£å¸¸ï¼Œå¯ç»§ç»­å½“å‰æ´»åŠ¨ (40-59åˆ†)
- âœ… çŠ¶æ€è‰¯å¥½ï¼Œå¯é€‚å½“å¢åŠ æŒ‘æˆ˜æ€§å†…å®¹ (60-74åˆ†)
- ğŸ‰ çŠ¶æ€æä½³ï¼ç»§ç»­ä¿æŒå½“å‰çš„å­¦ä¹ /å·¥ä½œèŠ‚å¥ (75-100åˆ†)

## ğŸ› ï¸ éƒ¨ç½²è¦æ±‚

### ç¯å¢ƒä¾èµ–
```bash
pip install torch torchvision opencv-python flask numpy
```

### ç³»ç»Ÿè¦æ±‚
- Python 3.8+
- PyTorch 1.8+
- CUDAæ”¯æŒï¼ˆå¯é€‰ï¼ŒCPUä¹Ÿå¯è¿è¡Œï¼‰
- å†…å­˜: è‡³å°‘2GB
- å­˜å‚¨: æ¨¡å‹æ–‡ä»¶çº¦2.4MB

### æ–‡ä»¶æ¸…å•
- `best_fast_daisee_model.pth` - è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡
- `emotion_recognition_api.py` - APIæ ¸å¿ƒä»£ç 
- `test_emotion_api.py` - æµ‹è¯•éªŒè¯è„šæœ¬
- `demo_api_usage.py` - ä½¿ç”¨æ¼”ç¤º
- `API_é›†æˆè¯´æ˜.md` - æœ¬æ–‡æ¡£

## ğŸ”§ é›†æˆæŒ‡å—

### å‰ç«¯é›†æˆç¤ºä¾‹

#### Reactç»„ä»¶
```jsx
import React, { useState } from 'react';

function EmotionAnalyzer() {
  const [result, setResult] = useState(null);
  
  const analyzeVideo = async (videoFile) => {
    const formData = new FormData();
    formData.append('video', videoFile);
    
    const response = await fetch('/predict_file', {
      method: 'POST',
      body: formData
    });
    
    const data = await response.json();
    setResult(data);
  };
  
  return (
    <div>
      {result && (
        <div>
          <h3>æƒ…æ„Ÿåˆ†æç»“æœ</h3>
          <p>æœ€ç»ˆå¾—åˆ†: {result.final_score.toFixed(2)}/100</p>
          <p>ä¸»å¯¼æƒ…æ„Ÿ: {result.dominant_emotion}</p>
          <p>è§£é‡Š: {result.interpretation}</p>
          
          <h4>æƒ…æ„Ÿå æ¯”:</h4>
          {Object.entries(result.emotions.percentages).map(([emotion, pct]) => (
            <div key={emotion}>
              {emotion}: {pct.toFixed(1)}%
            </div>
          ))}
        </div>
      )}
    </div>
  );
}
```

#### Vueç»„ä»¶
```vue
<template>
  <div>
    <input type="file" @change="handleVideoUpload" accept="video/*">
    
    <div v-if="result">
      <h3>æƒ…æ„Ÿåˆ†æç»“æœ</h3>
      <p>æœ€ç»ˆå¾—åˆ†: {{ result.final_score.toFixed(2) }}/100</p>
      <p>ä¸»å¯¼æƒ…æ„Ÿ: {{ result.dominant_emotion }}</p>
      <p>è§£é‡Š: {{ result.interpretation }}</p>
      
      <div v-for="(pct, emotion) in result.emotions.percentages" :key="emotion">
        {{ emotion }}: {{ pct.toFixed(1) }}%
      </div>
    </div>
  </div>
</template>

<script>
export default {
  data() {
    return {
      result: null
    }
  },
  methods: {
    async handleVideoUpload(event) {
      const file = event.target.files[0];
      const formData = new FormData();
      formData.append('video', file);
      
      const response = await fetch('/predict_file', {
        method: 'POST',
        body: formData
      });
      
      this.result = await response.json();
    }
  }
}
</script>
```

### åç«¯é›†æˆç¤ºä¾‹

#### Express.jsä¸­é—´ä»¶
```javascript
const multer = require('multer');
const axios = require('axios');

const upload = multer({ dest: 'uploads/' });

app.post('/analyze-emotion', upload.single('video'), async (req, res) => {
  try {
    const formData = new FormData();
    formData.append('video', fs.createReadStream(req.file.path));
    
    const response = await axios.post('http://localhost:5000/predict_file', formData);
    
    res.json(response.data);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});
```

#### Djangoè§†å›¾
```python
from django.views.decorators.csrf import csrf_exempt
import requests

@csrf_exempt
def analyze_emotion(request):
    if request.method == 'POST' and request.FILES.get('video'):
        video_file = request.FILES['video']
        
        files = {'video': video_file}
        response = requests.post('http://localhost:5000/predict_file', files=files)
        
        return JsonResponse(response.json())
    
    return JsonResponse({'error': 'Invalid request'}, status=400)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡å¤„ç†
```python
# å¤„ç†å¤šä¸ªè§†é¢‘æ—¶ï¼Œå¯ä»¥æ‰¹é‡åŠ è½½æ¨¡å‹
api = EmotionRecognitionAPI()
results = []
for video_path in video_list:
    result = api.predict_emotions(video_path, is_base64=False)
    results.append(result)
```

### 2. å¼‚æ­¥å¤„ç†
```python
import asyncio
import aiofiles

async def analyze_video_async(video_path):
    # å¼‚æ­¥è§†é¢‘å¤„ç†
    api = EmotionRecognitionAPI()
    return api.predict_emotions(video_path, is_base64=False)
```

### 3. ç¼“å­˜æœºåˆ¶
```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=100)
def cached_predict(video_hash):
    api = EmotionRecognitionAPI()
    return api.predict_emotions(video_path, is_base64=False)
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

### 1. è§†é¢‘æ ¼å¼æ”¯æŒ
- æ”¯æŒæ ¼å¼: MP4, AVI, MOV, MKVç­‰å¸¸è§æ ¼å¼
- å»ºè®®åˆ†è¾¨ç‡: ä¸ä½äº128Ã—128
- å»ºè®®æ—¶é•¿: 3-30ç§’ï¼ˆç”¨äºæå–8å¸§ï¼‰

### 2. é”™è¯¯å¤„ç†
```python
try:
    result = api.predict_emotions(video_path)
except FileNotFoundError:
    print("è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
except ValueError as e:
    print(f"è§†é¢‘å¤„ç†é”™è¯¯: {e}")
except RuntimeError as e:
    print(f"æ¨¡å‹é¢„æµ‹é”™è¯¯: {e}")
```

### 3. èµ„æºç®¡ç†
- APIå®ä¾‹å¯é‡å¤ä½¿ç”¨ï¼Œé¿å…é¢‘ç¹åˆå§‹åŒ–
- å¤§æ–‡ä»¶å¤„ç†æ—¶æ³¨æ„å†…å­˜æ¸…ç†
- ä¸´æ—¶æ–‡ä»¶ä¼šè‡ªåŠ¨æ¸…ç†

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### éªŒè¯è„šæœ¬
è¿è¡Œä»¥ä¸‹è„šæœ¬éªŒè¯å®‰è£…å’Œé…ç½®ï¼š
```bash
python test_emotion_api.py      # å®Œæ•´éªŒè¯
python demo_api_usage.py       # ä½¿ç”¨æ¼”ç¤º
```

### å¸¸è§é—®é¢˜
1. **æ¨¡å‹åŠ è½½å¤±è´¥**: æ£€æŸ¥ `best_fast_daisee_model.pth` æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. **CUDAé”™è¯¯**: ç¡®ä¿PyTorchç‰ˆæœ¬ä¸CUDAç‰ˆæœ¬åŒ¹é…
3. **è§†é¢‘è§£ç é”™è¯¯**: å®‰è£… `opencv-python` å¹¶ç¡®ä¿è§†é¢‘æ–‡ä»¶å®Œæ•´
4. **å†…å­˜ä¸è¶³**: å‡å°‘æ‰¹æ¬¡å¤§å°æˆ–ä½¿ç”¨CPUæ¨¡å¼

---

ğŸ‰ **é›†æˆå®Œæˆï¼ç°åœ¨æ‚¨å¯ä»¥è·å¾—:**
- âœ… å››ä¸ªæƒ…æ„Ÿæ ‡ç­¾çš„è¯¦ç»†åˆ†æ
- âœ… å„æƒ…æ„Ÿçš„ç²¾ç¡®å æ¯”
- âœ… 0-100åˆ†çš„ç»¼åˆè¯„åˆ†
- âœ… æ™ºèƒ½åŒ–çš„çŠ¶æ€è§£é‡Š
- âœ… å®æ—¶æ€§èƒ½ä¿è¯ 